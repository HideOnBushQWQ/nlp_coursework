# 中英双语命名实体识别系统 - 实现说明文档

## 1. 项目概述

本项目实现了一个完整的中英双语命名实体识别（NER）系统，支持BERT、RoBERTa和BiLSTM-CRF三种模型，提供完整的数据预处理、模型训练、评估和推理功能。

### 1.1 实现特点

- ✅ **多模型支持**：实现了3种深度学习模型
- ✅ **双语支持**：同时支持中文和英文NER
- ✅ **模块化设计**：清晰的代码结构，易于维护
- ✅ **完整流程**：从数据加载到模型部署的完整pipeline
- ✅ **可视化展示**：丰富的训练过程和结果可视化
- ✅ **配置驱动**：使用YAML配置文件管理实验

### 1.2 技术栈

| 组件 | 技术 | 版本 |
|------|------|------|
| 深度学习框架 | PyTorch | ≥1.10.0 |
| 预训练模型 | Transformers | ≥4.20.0 |
| CRF层 | pytorch-crf | ≥0.7.2 |
| NER评估 | seqeval | ≥1.2.2 |
| 数据处理 | pandas, numpy | - |
| 可视化 | matplotlib, seaborn | - |

## 2. 代码结构说明

### 2.1 目录组织

```
nlp_coursework/
├── src/                          # 源代码
│   ├── data_preprocessing/       # 数据预处理
│   │   ├── dataset_loader.py     # 数据加载器
│   │   └── label_encoder.py      # 标签编码器
│   ├── models/                   # 模型实现
│   │   ├── base_model.py         # 基类
│   │   ├── bert_ner.py           # BERT模型
│   │   ├── roberta_ner.py        # RoBERTa模型
│   │   └── bilstm_crf.py         # BiLSTM-CRF
│   ├── training/                 # 训练模块
│   │   ├── trainer.py            # 训练器
│   │   └── utils.py              # 工具函数
│   ├── evaluation/               # 评估模块
│   │   ├── metrics.py            # 评估指标
│   │   └── evaluator.py          # 评估器
│   ├── inference/                # 推理模块
│   │   └── predictor.py          # 推理器
│   └── visualization/            # 可视化
│       ├── plot_metrics.py       # 指标可视化
│       └── display_entities.py   # 实体展示
├── scripts/                      # 脚本
│   ├── train.py                  # 训练脚本
│   ├── evaluate.py               # 评估脚本
│   └── predict.py                # 推理脚本
├── tests/                        # 测试
├── configs/                      # 配置文件
└── docs/                         # 文档
```

### 2.2 代码统计

| 模块 | 文件数 | 代码行数 | 说明 |
|------|--------|----------|------|
| 数据预处理 | 2 | ~400 | 数据加载、标签编码 |
| 模型 | 4 | ~600 | 3个模型+基类 |
| 训练 | 2 | ~400 | 训练器、早停 |
| 评估 | 2 | ~300 | 指标计算、对比 |
| 推理 | 1 | ~300 | 单句/批量推理 |
| 可视化 | 2 | ~400 | 图表、实体展示 |
| 脚本 | 3 | ~400 | 训练/评估/推理 |
| 测试 | 3 | ~200 | 单元测试 |
| **总计** | **19** | **~3000** | - |

## 3. 核心模块实现

### 3.1 数据预处理模块

#### 3.1.1 数据加载器 (`dataset_loader.py`)

**功能**：加载CoNLL格式的NER数据集

**关键类**：
- `CoNLLDatasetLoader`：解析CoNLL格式文件
- `NERDataset`：PyTorch Dataset实现
- `BiLSTMDataset`：BiLSTM专用Dataset

**核心逻辑**：

```python
# 标签对齐到子词
def _align_labels(self, tokens, labels, word_ids):
    aligned_labels = []
    previous_word_id = None
    for word_id in word_ids:
        if word_id is None:  # 特殊token
            aligned_labels.append(-100)
        elif word_id != previous_word_id:  # 新词的第一个子词
            aligned_labels.append(self.label_encoder.encode(labels[word_id]))
        else:  # 后续子词
            aligned_labels.append(-100)
        previous_word_id = word_id
    return aligned_labels
```

**特点**：
- 支持中英文数据
- 自动处理子词对齐
- 错误容忍机制

#### 3.1.2 标签编码器 (`label_encoder.py`)

**功能**：标签字符串与ID互相转换

**关键方法**：
- `encode()` / `decode()`：单个标签转换
- `encode_batch()` / `decode_batch()`：批量转换
- `save()` / `load()`：保存和加载

**标签定义**：
```python
labels = ['O']  # 非实体
for entity_type in ['PER', 'LOC', 'ORG', 'MISC']:
    labels.extend([f'B-{entity_type}', f'I-{entity_type}'])
# 共9个标签
```

### 3.2 模型模块

#### 3.2.1 模型基类 (`base_model.py`)

**功能**：定义所有NER模型的统一接口

**关键方法**：
- `forward()`：前向传播（抽象方法）
- `predict()`：推理预测
- `save_pretrained()` / `from_pretrained()`：模型保存加载

#### 3.2.2 BERT-NER模型 (`bert_ner.py`)

**架构**：
```
BERT Encoder
    ↓
Dropout (0.1)
    ↓
Linear (hidden_size → num_labels)
    ↓
CRF (可选)
    ↓
Predictions
```

**关键实现**：

```python
class BertNER(BaseNERModel):
    def __init__(self, config):
        self.bert = BertModel.from_pretrained(config['pretrained_model'])
        self.dropout = nn.Dropout(config['dropout'])
        self.classifier = nn.Linear(hidden_size, num_labels)
        if config['use_crf']:
            self.crf = CRF(num_labels, batch_first=True)
    
    def forward(self, input_ids, attention_mask, labels=None):
        # BERT编码
        outputs = self.bert(input_ids, attention_mask)
        sequence_output = outputs.last_hidden_state
        
        # 分类
        logits = self.classifier(self.dropout(sequence_output))
        
        # CRF解码
        if self.use_crf:
            loss = -self.crf(logits, labels, mask)
            predictions = self.crf.decode(logits, mask)
        else:
            loss = CrossEntropyLoss(logits, labels)
            predictions = argmax(logits, dim=-1)
        
        return {'loss': loss, 'logits': logits, 'predictions': predictions}
```

**特点**：
- 使用预训练BERT权重
- 可选CRF层提升标签一致性
- 支持梯度累积和混合精度训练

#### 3.2.3 RoBERTa-NER模型 (`roberta_ner.py`)

**实现**：与BERT-NER类似，使用RoBERTa编码器

**区别**：
- 不同的tokenization方案
- 不同的预训练策略
- 通常性能略优于BERT

#### 3.2.4 BiLSTM-CRF模型 (`bilstm_crf.py`)

**架构**：
```
Embedding Layer
    ↓
Dropout
    ↓
BiLSTM (2 layers)
    ↓
Dropout
    ↓
Linear
    ↓
CRF
    ↓
Predictions
```

**关键实现**：

```python
class BiLSTMCRF(BaseNERModel):
    def __init__(self, config):
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(
            embedding_dim,
            hidden_dim // 2,
            num_layers=2,
            bidirectional=True,
            batch_first=True
        )
        self.classifier = nn.Linear(hidden_dim, num_labels)
        self.crf = CRF(num_labels, batch_first=True)
    
    def forward(self, input_ids, attention_mask, labels=None):
        # 词嵌入
        embeddings = self.embedding(input_ids)
        
        # BiLSTM（使用pack_padded_sequence优化）
        lengths = attention_mask.sum(dim=1)
        packed = pack_padded_sequence(embeddings, lengths, batch_first=True)
        lstm_out, _ = self.lstm(packed)
        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)
        
        # CRF
        logits = self.classifier(lstm_out)
        loss = -self.crf(logits, labels, mask)
        predictions = self.crf.decode(logits, mask)
        
        return {'loss': loss, 'logits': logits, 'predictions': predictions}
```

**特点**：
- 传统序列标注模型，参数量小
- 训练速度快
- 作为性能基线

### 3.3 训练模块

#### 3.3.1 训练器 (`trainer.py`)

**功能**：统一的模型训练接口

**核心流程**：

```python
class NERTrainer:
    def train(self):
        for epoch in range(num_epochs):
            # 训练一个epoch
            train_loss = self.train_epoch()
            
            # 验证
            val_metrics = self.evaluate(val_loader)
            val_f1 = val_metrics['f1']
            
            # 保存最优模型
            if val_f1 > best_f1:
                self.model.save_pretrained(best_model_path)
                best_f1 = val_f1
            
            # 早停检查
            self.early_stopping(val_f1)
            if self.early_stopping.should_stop:
                break
```

**优化策略**：
- **AdamW优化器**：weight decay = 0.01
- **学习率调度**：Warmup + 线性衰减
- **梯度裁剪**：max_grad_norm = 1.0
- **早停机制**：patience = 3

#### 3.3.2 工具函数 (`utils.py`)

**包含**：
- `EarlyStopping`：早停机制
- `set_seed()`：设置随机种子
- `save/load_checkpoint()`：检查点管理

### 3.4 评估模块

#### 3.4.1 评估指标 (`metrics.py`)

**使用seqeval库**：确保实体级别的严格评估

```python
from seqeval.metrics import precision_score, recall_score, f1_score

def compute_metrics(predictions, labels, label_encoder):
    # 转换为标签字符串
    pred_labels = [[label_encoder.decode(p) for p in pred] 
                   for pred in predictions]
    true_labels = [[label_encoder.decode(l) for l in label] 
                   for label in labels]
    
    # 计算指标
    precision = precision_score(true_labels, pred_labels)
    recall = recall_score(true_labels, pred_labels)
    f1 = f1_score(true_labels, pred_labels)
    
    return {'precision': precision, 'recall': recall, 'f1': f1}
```

**评估指标**：
- Precision / Recall / F1（整体）
- 各实体类型的独立指标
- 混淆矩阵
- 实体级别准确率

#### 3.4.2 模型对比器 (`evaluator.py`)

**功能**：多模型性能对比

```python
class ModelComparator:
    def compare_models(self, models_results, save_path):
        results = []
        for model_name, (predictions, labels) in models_results.items():
            metrics = compute_metrics(predictions, labels)
            results.append({
                'Model': model_name,
                'Precision': metrics['precision'],
                'Recall': metrics['recall'],
                'F1-Score': metrics['f1']
            })
        
        df = pd.DataFrame(results)
        df.to_csv(save_path)
        return df
```

### 3.5 推理模块

#### 3.5.1 推理器 (`predictor.py`)

**功能**：模型推理和实体提取

**关键方法**：

```python
class NERPredictor:
    def predict(self, text):
        # 分词
        encoding = self.tokenizer(tokens, is_split_into_words=True)
        
        # 推理
        with torch.no_grad():
            predictions = self.model.predict(input_ids, attention_mask)
        
        # 对齐标签
        aligned_labels = self._align_predictions(predictions, word_ids)
        
        # 提取实体
        entities = self._extract_entities(tokens, aligned_labels)
        
        return {'text': text, 'tokens': tokens, 
                'labels': aligned_labels, 'entities': entities}
    
    def predict_batch(self, texts, batch_size=32):
        # 批量推理提高效率
        ...
```

**实体提取逻辑**：

```python
def _extract_entities(self, tokens, labels):
    entities = []
    entity_tokens = []
    entity_type = None
    
    for token, label in zip(tokens, labels):
        if label.startswith('B-'):
            if entity_tokens:
                # 保存上一个实体
                entities.append({
                    'text': ''.join(entity_tokens),
                    'type': entity_type,
                    'start': start,
                    'end': end
                })
            # 开始新实体
            entity_tokens = [token]
            entity_type = label[2:]
        elif label.startswith('I-') and entity_tokens:
            entity_tokens.append(token)
        else:  # 'O'
            if entity_tokens:
                entities.append(...)
            entity_tokens = []
    
    return entities
```

### 3.6 可视化模块

#### 3.6.1 训练可视化 (`plot_metrics.py`)

**功能**：绘制训练曲线和模型对比图

**实现的图表**：
1. **训练历史**：损失曲线、F1曲线、学习率曲线
2. **模型对比**：多模型性能柱状图
3. **混淆矩阵**：标签混淆热力图
4. **实体分布**：各类实体数量分布

#### 3.6.2 实体展示 (`display_entities.py`)

**功能**：实体高亮显示

**实现方式**：
- HTML格式展示
- 不同实体类型使用不同颜色
- 支持Jupyter Notebook显示
- 可导出为HTML文件

## 4. 脚本使用说明

### 4.1 训练脚本 (`scripts/train.py`)

**命令**：
```bash
python scripts/train.py --config configs/bert_chinese.yaml
```

**参数**：
- `--config`：配置文件路径
- `--device`：设备（cuda/cpu）

**配置文件示例** (`configs/bert_chinese.yaml`)：
```yaml
model:
  type: "bert"
  pretrained_model: "bert-base-chinese"
  num_labels: 9
  dropout: 0.1
  use_crf: true

training:
  batch_size: 16
  learning_rate: 3e-5
  num_epochs: 10
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0
  patience: 3

data:
  train_file: "data/raw/chinese/train.txt"
  dev_file: "data/raw/chinese/dev.txt"
  test_file: "data/raw/chinese/test.txt"
  max_length: 128

output:
  save_dir: "experiments/bert_chinese"
```

### 4.2 评估脚本 (`scripts/evaluate.py`)

**命令**：
```bash
python scripts/evaluate.py \
    --model_path experiments/bert_chinese/best_model \
    --config configs/bert_chinese.yaml \
    --output_file results/eval_results.json
```

### 4.3 推理脚本 (`scripts/predict.py`)

**单句推理**：
```bash
python scripts/predict.py \
    --model_path experiments/bert_chinese/best_model \
    --model_type bert \
    --pretrained_model bert-base-chinese \
    --text "张三在北京大学工作"
```

**批量推理**：
```bash
python scripts/predict.py \
    --model_path experiments/bert_chinese/best_model \
    --model_type bert \
    --pretrained_model bert-base-chinese \
    --input_file data/test.txt \
    --output_file results/predictions.json
```

## 5. 关键技术实现

### 5.1 子词标签对齐

**问题**：WordPiece/BPE分词会将词切分为子词，导致标签数量不匹配

**解决方案**：
- 策略1：只保留第一个子词的标签
- 后续子词标签设为-100（在loss计算中忽略）
- 使用`word_ids`进行对齐

### 5.2 CRF层集成

**目的**：约束标签转移的合法性

**实现**：
```python
from torchcrf import CRF

self.crf = CRF(num_labels, batch_first=True)

# 训练时计算负对数似然
loss = -self.crf(logits, labels, mask=mask, reduction='mean')

# 推理时使用Viterbi解码
predictions = self.crf.decode(logits, mask=mask)
```

**优势**：
- 避免非法标签序列（如I-PER直接跟在B-LOC后）
- 通常能提升1-2个百分点的F1

### 5.3 批处理优化

**技术**：
- 使用DataLoader的num_workers进行多进程数据加载
- 动态padding减少计算量
- BiLSTM使用pack_padded_sequence优化

### 5.4 混合精度训练（可选）

**实现**：
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    outputs = model(input_ids, attention_mask, labels)
    loss = outputs['loss']

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

**效果**：训练速度提升约30-50%

## 6. 性能优化

### 6.1 训练优化

1. **学习率调度**：Warmup + 线性衰减
2. **梯度累积**：模拟大batch size
3. **早停机制**：避免过拟合
4. **梯度裁剪**：防止梯度爆炸

### 6.2 推理优化

1. **批处理**：批量推理提高吞吐量
2. **模型量化**（可选）：FP32 → FP16/INT8
3. **ONNX导出**（可选）：跨平台部署

### 6.3 内存优化

1. **梯度检查点**：减少内存占用
2. **动态padding**：避免不必要的计算
3. **及时释放**：del不需要的中间变量

## 7. 测试说明

### 7.1 单元测试

**运行**：
```bash
python -m unittest discover tests
```

**覆盖**：
- 数据加载和标签编码
- 模型前向传播
- 评估指标计算

### 7.2 集成测试

**测试流程**：
1. 加载小规模测试数据
2. 训练模型1-2个epoch
3. 评估模型性能
4. 测试推理功能

## 8. 扩展性设计

### 8.1 添加新模型

1. 继承`BaseNERModel`基类
2. 实现`forward()`方法
3. 在`__init__.py`中注册
4. 创建对应的配置文件

### 8.2 支持新数据集

1. 实现数据加载器
2. 统一为CoNLL格式
3. 更新配置文件

### 8.3 添加新评估指标

在`src/evaluation/metrics.py`中添加函数

## 9. 常见问题

### 9.1 显存不足

**解决方案**：
- 减小batch size
- 减小max_length
- 使用梯度累积
- 使用混合精度训练

### 9.2 训练过慢

**解决方案**：
- 增大batch size（如果显存允许）
- 使用多GPU训练
- 使用混合精度训练
- 减小模型大小（如使用BERT-small）

### 9.3 F1分数低

**解决方案**：
- 检查数据质量
- 调整学习率
- 增加训练epoch
- 使用CRF层
- 尝试不同的预训练模型

## 10. 总结

本系统实现了一个完整、模块化的NER解决方案，具有以下特点：

1. **完整性**：涵盖数据处理、训练、评估、推理全流程
2. **模块化**：清晰的代码结构，易于维护和扩展
3. **通用性**：支持多语言、多模型、多数据集
4. **工程化**：配置驱动、日志完善、错误处理
5. **可视化**：丰富的训练过程和结果展示

总代码量约3000行，实现了需求文档中的所有功能点。
